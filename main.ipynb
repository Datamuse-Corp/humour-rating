{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humour Rating Generation\n",
    "\n",
    "Run in order unless specified otherwise in Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_COCKAMAMIE_DATA_SRC = \"data/cockamamie_gobbledegook_us_data.json\"\n",
    "_DATAMUSE_DATA_SRC = \"data/ol_gte2.2022-09-26.words\"\n",
    "_EH_DATA_SRC = \"data/humor_dataset.csv\"\n",
    "\n",
    "_VEC_SRC = \"data/wiki-news-300d-1M-subword.vec\"\n",
    "_PKL_SRC = \"data/wiki-news-300d-1M-subword.pkl\"\n",
    "\n",
    "_OUTPUT_SRC = \"output.json\"\n",
    "\n",
    "_COMPONENT_KEYS = [\"snd\", \"scatc\", \"clq\", \"inslt\", \"juxt\", \"sexc\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run **only one** of the two next blocks.\n",
    "\n",
    "Run the 1st block to find humour scores for Cockamamie Gobbledegook words.\n",
    "\n",
    "Run the 2nd block to find humour scores for Datamuse words (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load sample_words from Cockamamie Gobbledegook data.\n",
    "\"\"\"\n",
    "\n",
    "with open(_COCKAMAMIE_DATA_SRC, \"r\") as f:\n",
    "    user_data = json.load(f)\n",
    "    votes = user_data[\"word_ratings\"][\"votes\"]\n",
    "\n",
    "sample_words = [sorted(ws) for ws in votes][0]  # 0th index for all 128k words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load sample_words from Datamuse data.\n",
    "\"\"\"\n",
    "\n",
    "with open(_DATAMUSE_DATA_SRC, \"r\") as f:\n",
    "    sample_words = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load training data for overall score from the EH dataset.\n",
    "\"\"\"\n",
    "\n",
    "with open(_EH_DATA_SRC, \"r\") as f:\n",
    "    cells = [line.strip().split(\",\") for line in f.readlines()]\n",
    "    headings = cells[0][1:]\n",
    "    entries = {\n",
    "        row[0]: {feat: float(v) for v, feat in zip(row[1:], headings)}\n",
    "        for row in cells[1:]\n",
    "    }\n",
    "\n",
    "overall_training_data = {w: entries[w][\"mean\"] for w in entries}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load training data for component scores from the Cockamamie Gobbledegook dataset.\n",
    "\"\"\"\n",
    "\n",
    "with open(_COCKAMAMIE_DATA_SRC, \"r\") as f:\n",
    "    component_training_data = json.load(f)[\"word_features\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_words = list(overall_training_data) + list(component_training_data[\"snd\"]) + sample_words  # combine all seen words\n",
    "testing_words = list(set(testing_words))  # remove duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the \"Pickle the `.vec` file\" section to create/update the `.pkl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predict the humour score of all words.\n",
    "Outputs (word, humour score) pairs (.json) and ordered list (by humour) (.txt).\n",
    "\"\"\"\n",
    "\n",
    "def append_to_output_data(data, training_data, output_key):\n",
    "    with open(_PKL_SRC, \"rb\") as f:\n",
    "        E = pkl.load(f)\n",
    "\n",
    "    clr = LinearRegression()\n",
    "    clr.fit([E[w] for w in training_data], [training_data[w] for w in training_data])\n",
    "    predictions = {\n",
    "        w: float(v)\n",
    "        for (w, v) in zip(testing_words, clr.predict([E[w] for w in testing_words]))\n",
    "    }\n",
    "    humour_order = [\n",
    "        w for w in sorted(testing_words, key=lambda x: predictions[x], reverse=True)\n",
    "    ]\n",
    "\n",
    "    for word, score in predictions.items():\n",
    "        data[word][output_key] = score\n",
    "    \n",
    "    return data\n",
    "\n",
    "def export_output_data(data):\n",
    "    with open(_OUTPUT_SRC, \"w\") as f:\n",
    "        print(json.dumps(data), file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = defaultdict(lambda: dict())\n",
    "\n",
    "output_data = append_to_output_data(output_data, overall_training_data, \"overall\")\n",
    "for key in _COMPONENT_KEYS:\n",
    "    output_data = append_to_output_data(output_data, component_training_data[key], key)\n",
    "\n",
    "export_output_data(output_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the `.vec` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_file2dict(vec_filename, pkl_filename):\n",
    "\n",
    "    e = KeyedVectors.load_word2vec_format(vec_filename)\n",
    "\n",
    "    def get_word(w):\n",
    "        try:\n",
    "            v = e[w.replace(\"_\", \" \")]\n",
    "            return v / np.linalg.norm(v)  # normalize v\n",
    "        except:\n",
    "            return 0.0 * e[\"cat\"]\n",
    "\n",
    "    e_dict = {w: get_word(w) for w in testing_words}\n",
    "    with open(pkl_filename, \"wb\") as f:\n",
    "        pkl.dump(e_dict, f)\n",
    "\n",
    "    non_zero_vectors = [v for v in e_dict.values() if not np.allclose(v, 0)]\n",
    "    print(\n",
    "        f'Loaded \"{vec_filename}\" and wrote {len(non_zero_vectors):,} non-zero vectors to \"{pkl_filename}\"'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_file2dict(_VEC_SRC, _PKL_SRC)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('humour_rating-HazLYBI6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d0a4cf747db125b17fde6516414a29aa55d7f5385057e722e4e0b0c49bdc7bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
